{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J22mde3KxPgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opCac3aqx0ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA2AaMD6x6Lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j7mh6zi2KKG",
        "colab_type": "text"
      },
      "source": [
        "The following function will process the data before it is fed into the model for training or predicting. Sex will be encoded with one-hot encoding scheme as sex is not ordinal. There is no need to normalize other features. When selecting a feature to split, information gain will not be influenced by the magnitute of values. When preprocessing data, I am replacing all missing data with 0. It is not the ideal approach, however, because it affects the split of feature with missing data. Will re-approach this issue later. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2163KV2pOXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def processData(data):\n",
        "  copy = data.drop(['Sex'], axis=1)\n",
        "  copy.fillna(0, inplace=True) #Replacing all missing data with 0\n",
        "  copy['Cabin'][copy['Cabin'] != 0] = 1\n",
        "  xEncoder = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
        "  x1 = data[['Sex']]\n",
        "  xEncoder.fit(x1)\n",
        "  x1 = xEncoder.transform(x1).toarray()\n",
        "  df = pd.DataFrame(data=x1, columns=['Male', 'Female'])\n",
        "  output = pd.concat([copy, df], axis=1)\n",
        "  #preprocessing.normalize(output, axis=1, copy=False) There is no need to normalize\n",
        "  #print(output.head())\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCBpNV0T0Sjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Dataset/Titanic/train.csv', header=0)\n",
        "train, test = train_test_split(df, test_size=0.2)\n",
        "train.reset_index(inplace=True)\n",
        "test.reset_index(inplace=True)\n",
        "trainX = train.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Embarked'], axis=1)\n",
        "testX = test.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Embarked'], axis=1)\n",
        "trainY = train[['Survived']]\n",
        "testY = test[['Survived']]\n",
        "trainX = processData(trainX)\n",
        "testX = processData(testX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YWImaWr5G5H",
        "colab_type": "code",
        "outputId": "e4691760-cad3-44e3-b139-c08a61f15ffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "DT = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "DT.fit(trainX, trainY)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
              "                       max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort=False,\n",
              "                       random_state=42, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdELKEC70pKE",
        "colab_type": "code",
        "outputId": "050e304f-1c95-4e72-8151-2aeab0581226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "DT.score(testX, testY)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7206703910614525"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYsgOPobIPW6",
        "colab_type": "code",
        "outputId": "41176ffe-2b0f-4d9a-9d88-335db4ce4132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "RF = RandomForestClassifier(criterion='entropy')\n",
        "RF.fit(trainX, trainY)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uux_ye9NItyg",
        "colab_type": "code",
        "outputId": "fba31d1b-c29d-4bed-ccf0-99c5dc79a4ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "RF.score(testX, testY)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.776536312849162"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLmSEQE-NkQc",
        "colab_type": "text"
      },
      "source": [
        "Train a single decision tree model with some hyperparameter tuning using grid search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQJ4XR3KRTK0",
        "colab_type": "code",
        "outputId": "932bd904-feac-466b-f8d8-acee188ac388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "#tree.plot_tree(DT)\n",
        "hyperPara = {'splitter':['best', 'random'], 'criterion':['gini', 'entropy'], 'min_samples_leaf':range(1, 21), 'min_samples_split':range(2, 41), 'min_impurity_decrease':np.linspace(0, 1, 11)}\n",
        "#gridSearch = GridSearchCV(DT, hyperPara)\n",
        "gridSearch = GridSearchCV(DecisionTreeClassifier(random_state=42), hyperPara)\n",
        "gridSearch.fit(trainX, trainY)\n",
        "print(gridSearch.best_params_)\n",
        "gridSearch.best_estimator_.score(testX, testY)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'criterion': 'entropy', 'min_impurity_decrease': 0.0, 'min_samples_leaf': 3, 'min_samples_split': 10, 'splitter': 'random'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7988826815642458"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}